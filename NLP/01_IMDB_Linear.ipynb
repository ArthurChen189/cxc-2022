{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd0a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad9e17a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"C://Users//alvin//DATA//dsc//cxc-2022//data//imdb_ds.csv\"\n",
    "\n",
    "raw_ds = pd.read_csv(data_path)\n",
    "raw_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac7f39bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_ds[\"sentiment\"].value_counts()\n",
    "\n",
    "# perfectly balanced as all things should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e488e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  sentiment_num\n",
       "0  One of the other reviewers has mentioned that ...  positive              1\n",
       "1  A wonderful little production. <br /><br />The...  positive              1\n",
       "2  I thought this was a wonderful way to spend ti...  positive              1\n",
       "3  Basically there's a family where a little boy ...  negative              0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive              1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_dict = {\n",
    "    \"positive\": 1,\n",
    "    \"negative\": 0\n",
    "}\n",
    "\n",
    "raw_ds[\"sentiment_num\"] = raw_ds[\"sentiment\"].map(sentiment_dict)\n",
    "raw_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab2a7e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a wonderful little production br br the filming technique is very unassuming very oldtimebbc fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece br br the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece a masterful production about one of the great masters of comedy and his life br br the realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwells murals decorating every surface are terribly well done'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def cleanup(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    return sentence\n",
    "\n",
    "cleanup(raw_ds[\"review\"].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29449326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "glove_path = \"C://Users//alvin//DATA//dsc//cxc-2022//NLP//glove.6B.50d.txt\"\n",
    "glove_dict = dict()\n",
    "with open(glove_path,'r', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], np.float32)\n",
    "        glove_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b90d32fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "words, mats = glove_dict.keys(), np.stack(list(glove_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63dcaf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "mats_10 = pca.fit_transform(mats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1da7372",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dict_10 = dict()\n",
    "for i, word in enumerate(words):\n",
    "    glove_dict_10[word] = mats_10[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bb80b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello: [ 1.7819184   0.9185053   0.27074027 -1.556231    1.1623983  -0.28482863\n",
      " -1.002999    0.7611644   0.51761925 -0.3000517 ] \n",
      "\n",
      "kjnkejnv: [0.90342017 0.40820559 0.18307293 0.70557698 0.18682414 0.55792556\n",
      " 0.09812458 0.40294489 0.83655341 0.34016838]\n"
     ]
    }
   ],
   "source": [
    "def vectorize_glove(word):\n",
    "    if word in glove_dict.keys():\n",
    "        return glove_dict_10[word]\n",
    "    else:\n",
    "        return np.random.random((10))\n",
    "    \n",
    "print(\"hello: {} \\n\\nkjnkejnv: {}\".format(vectorize_glove(\"hello\"), vectorize_glove(\"kjnkejnv\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e08e7f44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.46019065,  0.10174885,  0.2349833 ,  0.13381507,  0.13139261,\n",
       "        -0.35644269,  0.13025667,  0.88861185, -0.53457463,  0.28422403],\n",
       "       [ 3.91869497,  2.20386267,  0.37218884, -1.4228698 ,  0.74477488,\n",
       "         0.23443703, -0.41543913,  0.64290857,  0.8048414 , -0.85233623],\n",
       "       [ 4.72919226,  3.22979999, -0.10978653, -1.31802189,  0.91205353,\n",
       "        -0.45005161,  0.00574686,  0.87387037,  0.3075569 , -0.8312102 ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SENT_LEN = 50\n",
    "\n",
    "def vectorize_sentence(sentence):\n",
    "    sent_vec = []\n",
    "    words = list(reversed(nltk.word_tokenize(sentence)))\n",
    "    for i in range(MAX_SENT_LEN):\n",
    "        if i < len(words):\n",
    "            sent_vec.append(vectorize_glove(words[i]))\n",
    "        else:\n",
    "            sent_vec.append(np.zeros(10))\n",
    "            \n",
    "    return np.stack(sent_vec)\n",
    "\n",
    "vectorize_sentence(cleanup(\"I love maths\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52387619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, isTest=False):\n",
    "        self.raw_ds = pd.read_csv(data_path)\n",
    "        sentiment_dict = {\n",
    "            \"positive\": 1,\n",
    "            \"negative\": 0\n",
    "        }\n",
    "\n",
    "        self.raw_ds[\"sentiment_num\"] = self.raw_ds[\"sentiment\"].map(sentiment_dict)\n",
    "        \n",
    "        train_ds, test_ds = train_test_split(self.raw_ds, test_size=0.2, random_state=42)\n",
    "        if isTest:\n",
    "            self.ds = test_ds\n",
    "        else:\n",
    "            self.ds = train_ds\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        x = self.ds[\"review\"].iloc[idx]\n",
    "        y = self.ds[\"sentiment_num\"].iloc[idx]\n",
    "        return vectorize_sentence(cleanup(x)).flatten(), y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "train_sent = SentimentDataset()\n",
    "test_sent = SentimentDataset(False)\n",
    "\n",
    "train_iter = DataLoader(train_sent, batch_size=40, shuffle=True)\n",
    "test_iter = DataLoader(test_sent, batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f54f3163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape,128)\n",
    "        self.fc2 = nn.Linear(128,32)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(32,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.drop(self.fc3(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36467bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 60\n",
    "LR = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5140bd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed_all(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = LinearNet(50 * 10)\n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=LR)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e703e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---EPOCH 0---\n",
      "Train Acc 0.5111 || Loss 0.6924773454666138\n",
      "Test Acc 0.55065 || Loss 0.6890760660171509\n",
      "---EPOCH 1---\n",
      "Train Acc 0.535875 || Loss 0.6877182722091675\n",
      "Test Acc 0.5778 || Loss 0.6816287040710449\n",
      "---EPOCH 2---\n",
      "Train Acc 0.5539 || Loss 0.6814061403274536\n",
      "Test Acc 0.597925 || Loss 0.6723319292068481\n",
      "---EPOCH 3---\n",
      "Train Acc 0.5656 || Loss 0.6778176426887512\n",
      "Test Acc 0.60515 || Loss 0.6665642857551575\n",
      "---EPOCH 4---\n",
      "Train Acc 0.572475 || Loss 0.6729364991188049\n",
      "Test Acc 0.590025 || Loss 0.6683647036552429\n",
      "---EPOCH 5---\n",
      "Train Acc 0.57615 || Loss 0.6705861687660217\n",
      "Test Acc 0.61105 || Loss 0.6593706011772156\n",
      "---EPOCH 6---\n",
      "Train Acc 0.57995 || Loss 0.6690576672554016\n",
      "Test Acc 0.6055 || Loss 0.6619959473609924\n",
      "---EPOCH 7---\n",
      "Train Acc 0.581175 || Loss 0.6683685183525085\n",
      "Test Acc 0.599075 || Loss 0.6617356538772583\n",
      "---EPOCH 8---\n",
      "Train Acc 0.58735 || Loss 0.6666016578674316\n",
      "Test Acc 0.61645 || Loss 0.6555406451225281\n",
      "---EPOCH 9---\n",
      "Train Acc 0.5838 || Loss 0.6666612029075623\n",
      "Test Acc 0.61305 || Loss 0.6580079793930054\n",
      "---EPOCH 10---\n",
      "Train Acc 0.5955 || Loss 0.6596195101737976\n",
      "Test Acc 0.61515 || Loss 0.6556148529052734\n",
      "---EPOCH 11---\n",
      "Train Acc 0.598225 || Loss 0.6582010388374329\n",
      "Test Acc 0.618125 || Loss 0.6527349948883057\n",
      "---EPOCH 12---\n",
      "Train Acc 0.592775 || Loss 0.659260630607605\n",
      "Test Acc 0.6191 || Loss 0.6525228023529053\n",
      "---EPOCH 13---\n",
      "Train Acc 0.595225 || Loss 0.6589197516441345\n",
      "Test Acc 0.620675 || Loss 0.652073085308075\n",
      "---EPOCH 14---\n",
      "Train Acc 0.594625 || Loss 0.6588154435157776\n",
      "Test Acc 0.61915 || Loss 0.6518245339393616\n",
      "---EPOCH 15---\n",
      "Train Acc 0.5996 || Loss 0.6582152843475342\n",
      "Test Acc 0.61935 || Loss 0.651817798614502\n",
      "---EPOCH 16---\n",
      "Train Acc 0.59605 || Loss 0.6576514840126038\n",
      "Test Acc 0.6198 || Loss 0.6515250205993652\n",
      "---EPOCH 17---\n",
      "Train Acc 0.59625 || Loss 0.6580069065093994\n",
      "Test Acc 0.6215 || Loss 0.6513540148735046\n",
      "---EPOCH 18---\n",
      "Train Acc 0.59465 || Loss 0.6580755710601807\n",
      "Test Acc 0.62075 || Loss 0.6508578658103943\n",
      "---EPOCH 19---\n",
      "Train Acc 0.59565 || Loss 0.65859055519104\n",
      "Test Acc 0.620975 || Loss 0.6511961817741394\n",
      "---EPOCH 20---\n",
      "Train Acc 0.59725 || Loss 0.6573418974876404\n",
      "Test Acc 0.620475 || Loss 0.6507993936538696\n",
      "---EPOCH 21---\n",
      "Train Acc 0.597575 || Loss 0.6569837927818298\n",
      "Test Acc 0.6214 || Loss 0.650603175163269\n",
      "---EPOCH 22---\n",
      "Train Acc 0.59745 || Loss 0.6574384570121765\n",
      "Test Acc 0.621725 || Loss 0.6506664156913757\n",
      "---EPOCH 23---\n",
      "Train Acc 0.595975 || Loss 0.6576001644134521\n",
      "Test Acc 0.623125 || Loss 0.6506348848342896\n",
      "---EPOCH 24---\n",
      "Train Acc 0.5971 || Loss 0.6576043963432312\n",
      "Test Acc 0.621025 || Loss 0.65069979429245\n",
      "---EPOCH 25---\n",
      "Train Acc 0.59605 || Loss 0.657085657119751\n",
      "Test Acc 0.6225 || Loss 0.6505569815635681\n",
      "---EPOCH 26---\n",
      "Train Acc 0.598725 || Loss 0.6558729410171509\n",
      "Test Acc 0.620625 || Loss 0.6507319808006287\n",
      "---EPOCH 27---\n",
      "Train Acc 0.596375 || Loss 0.6569339036941528\n",
      "Test Acc 0.619975 || Loss 0.6505366563796997\n",
      "---EPOCH 28---\n",
      "Train Acc 0.595125 || Loss 0.657405436038971\n",
      "Test Acc 0.621425 || Loss 0.6506286859512329\n",
      "---EPOCH 29---\n",
      "Train Acc 0.598725 || Loss 0.6568366885185242\n",
      "Test Acc 0.62105 || Loss 0.6506146192550659\n",
      "---EPOCH 30---\n",
      "Train Acc 0.5962 || Loss 0.6574061512947083\n",
      "Test Acc 0.621325 || Loss 0.6503543257713318\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m test_iter:\n\u001b[0;32m     40\u001b[0m         x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     41\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(x\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    560\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    563\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36mSentimentDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     21\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[0;32m     22\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment_num\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvectorize_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten(), y\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mvectorize_sentence\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m         sent_vec\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent_vec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py:433\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out)\u001b[0m\n\u001b[0;32m    431\u001b[0m sl \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m),) \u001b[38;5;241m*\u001b[39m axis \u001b[38;5;241m+\u001b[39m (_nx\u001b[38;5;241m.\u001b[39mnewaxis,)\n\u001b[0;32m    432\u001b[0m expanded_arrays \u001b[38;5;241m=\u001b[39m [arr[sl] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_arrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "test_acc = []\n",
    "test_loss = []\n",
    "\n",
    "\n",
    "for ep_idx in range(EPOCHS):\n",
    "    model.train()\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "    losses = []\n",
    "    for x, y in train_iter:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        outputs = model(x.float())\n",
    "        outputs = torch.squeeze(outputs)\n",
    "        loss = loss_fn(outputs, y.float())\n",
    "        losses.append(loss.detach().numpy())\n",
    "        preds = outputs.detach().numpy() > 0.5\n",
    "        y_np = y.numpy()\n",
    "        \n",
    "        corrects += np.sum(preds==y_np)\n",
    "        total += len(x)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_acc.append(corrects/total)\n",
    "    train_loss.append(np.mean(losses))\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    model.eval()\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_iter:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x.float())\n",
    "            outputs = torch.squeeze(outputs)\n",
    "            loss = loss_fn(outputs, y.float())\n",
    "            losses.append(loss.detach().numpy())\n",
    "            preds = outputs.detach().numpy() > 0.5\n",
    "            y_np = y.numpy()\n",
    "\n",
    "            corrects += np.sum(preds==y_np)\n",
    "            total += len(x)\n",
    "            \n",
    "    test_acc.append(corrects/total)\n",
    "    test_loss.append(np.mean(losses))\n",
    "    \n",
    "    print(\"---EPOCH {}---\".format(ep_idx))\n",
    "    print(\"Train Acc {} || Loss {}\".format(train_acc[-1], train_loss[-1]))\n",
    "    print(\"Test Acc {} || Loss {}\".format(test_acc[-1], test_loss[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
